---
title: "Homework 4"
subtitle: <center> <h1>Multiple Linear Regression</h1> </center>
author: <center> < PUT YOUR NAME HERE > <center>
output: html_document
---

<style type="text/css">
h1.title {
  font-size: 40px;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  # needed for added-variable plots and dfbetas and dffits
library(corrplot)  # colored correlation matrix
library(gridExtra)  # NEW PACKAGE for putting multiple ggplots in one plot
library(grid) # To go along with gridExtra
```

*Note that you do not need to properly format the axis limits in your plots for this assignment (to save time). You should, however, still make the plots square in shape.*

## Data and Description

Measuring body fat is not simple. One method requires submerging the body underwater in a tank and measuring the increase in water level. A simpler method for estimating body fat would be preferred. In order to develop such a method, researchers recorded age (years), weight (pounds), height (inches), and three body circumference measurements (around the neck, chest, and abdominal (all in centimeters)) for 252 men. Each manâ€™s percentage of body fat was accurately estimated by an underwater weighing technique (the variable brozek is the percentage of body fat). The hope is to be able to use this data to create a model that will accurately predict body fat percentage, by using just the basic variables recorded, without having to use the tank submerging method. 

The data can be found in the BodyFat data set on Canvas. Download "BodyFat.txt", and put it in the same folder as this R Markdown file.

#### 0. Replace the text "< PUT YOUR NAME HERE >" (above next to "author:") with your full name.

#### 1. Read in the data set, and call the data frame "bodyfat". Print a summary of the data and make sure the data makes sense. 

```{r}
bodyfat <- read.csv("bodyfat.txt", sep = " ", row.names = 1)
bodyfat <- tibble(bodyfat)
summary(bodyfat)
```

#### 2. Create and print a scatterplot matrix of the data.

```{r, fig.align='center', fig.height=8, fig.width=8}
point_matrix <- function(data) {
  par(pty = "s", las = 1)
  pairs(data, pch = 19, lower.panel = NULL)
}
point_matrix(bodyfat)
```

#### 3. Based on the scatterplot matrix, briefly explain which variables you think will be "significant" for predicting brozek and which variables you think will *not* be helpful at predicting brozek. Explain how the scatterplot helped determine your answers.

I think that weight, neck chest and abdomen will be useful in predicting brozek because they seem to have moderate to strong linear relationships. The last two do not seem to have any correlation.

#### 4. Create and print a correlation matrix (numeric or color- and shape-coded).

```{r, fig.height=3}
show_cor <- function(data) {
  par(mfrow = c(1, 2))
  corrplot(cor(data), method = "number", type = "upper", diag = F, tl.col = "#1f3366", cl.pos = "n")
  corrplot(cor(data), type = "upper", diag = F, tl.col = "#1f3366", cl.pos = "n")
}
show_cor(bodyfat)
```

#### 5. Based on the scatterplot matrix and the correlation matrix, are their any pairs of variables that you suspect will cause a problem for the multicollinearity assumption? If so, which ones?

Weight has a strong correlation with neck, chest, and abdomen so that will definitly cause a problem. We should probably also keep and eye on neck with chest and abdomen.

#### 6. Fit a multiple linear regression model to the data (no transformations). Print a summary of the results. Save the residuals to the `bodyfat` data frame.

```{r}
bodyfat_lm <- lm(brozek ~ ., data = bodyfat)
summary(bodyfat_lm)
round(bodyfat_lm$coefficients, 3)
```

#### 7. Briefly comment on the "significance" of the variables: were you surprised by the results? Are there any variables that are significant that you think shouldn't be? Are there any variables that are not significant that you think should be?

The results mostly look okay, but chest should be significant. Our results are definitly being thrown off by a multi-colinearity problem.

#### 8. Briefly comment on the sign (+/-) of the coefficients for the variables. Are their any variables where the sign is the opposite of what you expected?

Weight and neck have a negative sign when I would expect them to be positive. IE I would expect people who weigh more and have larger necks to have more body fat.

#### 9. Mathematically write out the *fitted* multiple linear regression model for this data set using the coefficients you found above (do not use betas). Do not use "X" and "Y" in your model - use variable names that are fairly descriptive.

$\widehat{\text{brozek}}_i=-20.1+0.005\cdot\text{age}_i-0.087\cdot\text{weight}_i-0.140\cdot\text{height}_i-0.442\cdot\text{neck}_i+0.00048\cdot\text{chest}_i+0.875\cdot\text{abdomen}_i$

#### 10. *Assuming* the model assumptions are all met, how would you interpret the coefficient for Weight?

For people with the same measurements in every other area, a one pound increase in weight results in a 0.087 percent increase in body fat.

#### 11. Briefly explain what it means to "hold all else constant," when you interpret the coefficient for Weight?

"Holding all else constant" means that we are isolating the effect of one variable by looking at individuals with the same scores in all other categories.

#### 12. Briefly explain what the F-test indicates, as reported in the model output from question 6.

A p-value of $2.2\times10^{-16}$ indicates that at least one of the variables in our model has a significant effect on body fat.

#### 13. Briefly interpret the *adjusted* R-squared, as reported in the model output from question 6.

71% of the variability in body fat percentage can be explained by the predictors in our model.

### Questions 14-20 involve using diagnostics to determine if the linear regression assumptions are met. For each assumption, (1) perform appropriate diagnostics to determine if the assumption is violated, and (2) explain whether or not you think the assumption is violated and why you think that.

#### 14. (L) The X's vs Y are linear (use the residual vs. predictor plots, partial regression plots, and one other diagnostic tool of your choice). 

```{r, fig.align='center', fig.height=5, message=FALSE}
# residual vs. predictor plots
resid_vs_pred <- function(model) {
  data <- model.frame(model)
  predictors <- attr(model$terms, "term.labels")
  residuals <- resid(model)
  plots <- list()
  for (i in predictors) {
    plots[[i]] <- ggplot(data = data,
                         mapping = aes(x = pull(data, i),
                                       y = model$residuals)) +
      geom_point() +
      geom_smooth(span = 0.8, n= 10, size = 0.5, se = FALSE) +
      theme_minimal() +
      theme(aspect.ratio = 1) +
      xlab(i) +
      ylab("Residuals")
    plots[[i]]
  }
  plots["ncol"] <- ceiling(sqrt(length(plots)))
  #plots["top"] <- textGrob("Residuals vs Predictores", gp=gpar(fontsize=30))
  do.call(grid.arrange, plots)
}
resid_vs_pred(bodyfat_lm)
```

```{r, fig.align='center', fig.height=5}
# partial regression plots
added_variable_plots <- function(model) {
  predictors <- attr(model$terms, "term.labels")
  rows <- floor(sqrt(length(predictors)))
  cols <- length(predictors) / rows
  par(pty = "s", cex.lab = 1.5, cex.axis = 1.5)
  avPlots(model, layout = c(rows, cols), pch = 19)
}
added_variable_plots(bodyfat_lm)
```

```{r, fig.align='center', warning=FALSE}
resid_vs_fitted <- function(model) {
  autoplot(model, which = 1, ncol = 1) +
    theme_minimal() +
    theme(aspect.ratio = 1)
}
resid_vs_fitted(bodyfat_lm)
```

< your response here >

#### 15. (I) The residuals are independent (no diagnostic tools - just think about how the data was collected and briefly write your thoughts)

< your response here >

#### 16. (N) The residuals are normally distributed and centered at zero (use all four diagnostic tools)

```{r, fig.align='center'}
# Diagnostic 1
# your code here
```

```{r, fig.align='center'}
# Diagnostic 2
# your code here
```

```{r, fig.align='center'}
# Diagnostic 3
# your code here
```

```{r, fig.align='center'}
# Diagnostic 4
# your code here
```

< your response here >

#### 17. (E) The residuals have equal/constant variance across all values of X (only one diagnostic tool)

```{r, fig.align='center'}
# your code here
```

< your response here >

#### 18. (A) The model describes all observations (i.e., there are no influential points) (use Cook's distance, DFBETAS, and DFFITS. Also, in your response, refer to the evidence from the plots you created in previous questions)

```{r, fig.align='center'}
# Cook's Distance
# your code here
```

```{r, fig.align='center'}
# DFBETAS
# your code here
```

```{r, fig.align='center'}
# DFFITS
# your code here
```

< your response here >

#### 19. (R) Additional predictor variables are not required (no diagnostic tools - just think about the variables you have and if there are other variables you think would help predict the response)

< your response here >

#### 20. No multicollinearity (for this assumption, compute the variance inflation factors (VIFs) and compare the VIFs to your comments in questions 5. Do the variance inflation factors match your assumptions from questions 5? Is this assumption met?

```{r, fig.align='center'}
# your code here
```

< your response here >

### Note: your next homework assigment will use this same data set, and you will be asked to fix the assumptions that were broken.

#### 21. Briefly summarize what you learned, personally, from this analysis about the statistics, model fitting process, etc.

< your response here >

#### 22. Briefly summarize what you learned from this analysis *to a non-statistician*. Write a few sentences about (1) the purpose of this data set and analysis and (2) what you learned about this data set from your analysis. Write your response as if you were addressing a business manager (avoid using statistics jargon) and just provide the main take-aways.

< your response here >