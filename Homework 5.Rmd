---
title: "Homework 5"
subtitle: <center> <h1>Multiple Linear Regression Variable Selection Methods</h1> </center>
author: <center> Joshua Carpenter <center>
output: html_document
---

<style type="text/css">
h1.title {
font-size: 40px;
text-align: center;
}
</style>

```{r setup, include=FALSE}
library(gridExtra)  # NEW PACKAGE for putting multiple ggplots in one plot
library(tidyverse)
library(corrplot)  # colored correlation matrix
library(ggfortify)  # plot glmnet objects using ggplot instead of base R
library(car)  # needed for VIFs
library(bestglm)  # for stepwise methods
library(glmnet)  # for ridge, lasso, and elastic net
set.seed(6865)
```

### Data and Description

**For this assignment, we are revisiting the data set used in Homework 4. I think it would be very beneficial for you to review your Homework 4 before starting this one.**

*Note that you do not need to properly format the axis limits in your plots for this assignment (to save time). You should, however, still make the plots square in shape.*

Measuring body fat is not simple. One method requires submerging the body underwater in a tank and measuring the increase in water level. A simpler method for estimating body fat would be preferred. In order to develop such a method, researchers recorded age (years), weight (pounds), height (inches), and three body circumference measurements (around the neck, chest, and abdominal (all in centimeters)) for 252 men. Each man’s percentage of body fat was accurately estimated by an underwater weighing technique (the variable brozek is the percentage of body fat). The hope is to be able to use this data to create a model that will accurately predict body fat percentage, by using just the basic variables recorded, without having to use the tank submerging method. 

The data can be found in the BodyFat data set on Canvas. Download BodyFat.txt, and put it in the same folder as this R Markdown file.

#### 0. Replace the text "< PUT YOUR NAME HERE >" (above next to "author:") with your full name.

#### 0b. Make sure to set your seed since some of the functions randomly split your data (use `set.seed` in the setup code chunk above)!

#### 1. Read in the data set, and call the data frame "bodyfat_orig". Print a summary of the data and make sure the data makes sense. 

```{r}
bodyfat_orig <- read.csv("bodyfat.txt", sep = " ", row.names = 1)
(bodyfat_orig <- tibble(bodyfat_orig))
summary(bodyfat_orig)
```

#### 2. Refer back to your Homework 4. In that assignment, you fit this multiple linear regression model: for each of the multiple linear regression assumptions listed below, state if they were met or not met.

1. The X’s vs Y are linear:   Met
2. The residuals are normally distributed and centered at zero:   Met
3. The residuals are homoscedastic:   Met
4. The model describes all observations (i.e., there are no influential points):   Not met
5. No multicollinearity:   Not met

#### 3. There is one clear influential point in the data set. Create a new variable called "bodyfat" that contains the bodyfat_orig data set with the influential point removed. Use the bodyfat data set throughout the rest of the assignment.

```{r, fig.align='center'}
bodyfat <- bodyfat_orig %>%
  slice(-39)
```


### You should have discovered, from Homework 4, that there is a multicollinearity problem. The goal of this assignment is to continue this analysis by identifying variables to potentially remove from the model to resolve the multicollinearity issues. 




#### 4. Briefly explain why multicollinearity is a problem for multiple linear regression by identifying some (at least two) of the consequences of multicollinearity.

One of the consequences of multicollinearity is inflated variance which leads to wide confidence intervals. Another consequence is potentially inaccurate coefficients and hypothesis tests; variable can appear significant that aren't and vise versa and coefficients can have the opposite sign that they should.

#### 5. Briefly explain the similarities and differences between the following methods: best subset, forward, backward, and sequential replacement. Do not just copy the algorithm from the class notes - use your own words to explain what these methods are doing.

The best subset is the most thorough and preferable method. It compares all possible models and selects the best one. Forward selection is basically useless, but is the basis for the other two. It starts with an intercept model and adds variables that improve the model. Backward does the opposite; it starts with all variables and removes the ones that do not improve the model. Sequential starts with an intercept only model, adds variables one by one that improve the model and with each step also removes variables that don't improve the model. When best subsets is not possible, sequential replacement is probably the best bet.

#### 6. Briefly explain how shrinkage methods work (variance-bias tradeoff). Specifically, how can some of these methods be considered variable selection procedures?

Shrinkage methods introduce a little bit of bias in order to greatly reduce variance. Sometimes we are willing to make that trade off in order to get significant results.

#### 7. Briefly explain the similarities/difference between ridge regression, LASSO, and elastic net.

All three methods shrink coefficients, but ridge regression is not a variable selection method and therefore falls in a slightly different category than the other two. Each method applies a penalty to the normal OLS cost function for larger betas, then minimizes that cost function. In the case of LASSO and Elastic Net, some coefficients shrink to 0 leaving behind only the most useful variables. Elastic Net is quite similar to LASSO but overcomes some of it's limitations. Specifically, Elastic Net will sometimes select variables that are highly correlated leading to better predictions but potential problems with multicollinearity.


#### 8. Remember, when coding these methods, the response variable must be the last column in the data set for the `bestglm` function to work. Switch the order of the columns in the data set so that brozek is last.

```{r, fig.align='center'}
bodyfat <- bodyfat %>%
  select(age, weight, height, neck, chest, abdom, brozek)
bodyfat_df <- data.frame(bodyfat)
```

#### 9. Apply the best subsets variable selection procedure to this data set. You may choose which metric you would like to use (ex: AIC, BIC, PMSE). Output a summary of the "best" model.

```{r, fig.align='center'}
best_subsets <- bestglm(bodyfat_df, IC = "AIC", method = "exhaustive")
best_subsets$BestModels
summary(best_subsets$BestModel)

# Save the best models
best_models <- list()
best_models$best_subsets <- best_subsets$BestModel
```

#### 10. Apply the forward selection procedure to this data set. You may choose which metric you would like to use (ex: AIC, BIC, PMSE). Output a summary of the "best" model.

```{r, fig.align='center'}
forward <- bestglm(bodyfat_df, IC = "AIC", method = "forward")
forward$BestModels
summary(forward$BestModel)
best_models$forward <- forward$BestModel
```

#### 11. Apply the backward selection procedure to this data set. You may choose which metric you would like to use (ex: AIC, BIC, PMSE). Output a summary of the "best" model.

```{r, fig.align='center'}
backward <- bestglm(bodyfat_df, IC = "AIC", method = "backward")
backward$BestModels
summary(backward$BestModel)
best_models$backward <- backward$BestModel
```

#### 12. Apply the sequential replacement selection procedure to this data set. You may choose which metric you would like to use (ex: AIC, BIC, PMSE). Output a summary of the "best" model.

```{r, fig.align='center'}
seqrep <- bestglm(bodyfat_df, IC = "AIC", method = "seqrep")
seqrep$BestModels
summary(seqrep$BestModel)
best_models$seqrep <- seqrep$BestModel
```

#### 13. Apply LASSO to this data set using the MSE metric. Output the coefficient values corresponding to the 1 standard error rule (do not output any plots).

```{r, fig.align='center'}
bodyfat_predictors <- bodyfat %>%
  select(-brozek) %>%
  as.matrix()
bodyfat_response <- bodyfat %>%
  select(brozek) %>%
  as.matrix()

# Use cross validation to pick the best penalty parameter based on MSE
lasso <- cv.glmnet(x = bodyfat_predictors, y = bodyfat_response,
                           type.measure = "mse", alpha = 1)
# Plot log(lambda) against MSE
autoplot(lasso, label = FALSE) +
  theme_bw() +
  theme(aspect.ratio = 1)
# Pick the lambda value within 1 SE of the minimum MSE
lasso$lambda.1se
# Print the selected coefficients using the 1 SE lambda
(best_models$lasso <- coef(lasso, s = "lambda.1se"))
```

#### 14. Apply Elastic Net to this data set using the MSE metric. Output the coefficient values corresponding to the 1 standard error rule (do not output any plots).

```{r, fig.align='center'}
# Use cross validation to pick the best penalty parameter based on MSE
elastic <- cv.glmnet(x = bodyfat_predictors, y = bodyfat_response,
                           type.measure = "mse", alpha = 0.5)
# Plot log(lambda) against MSE
autoplot(elastic, label = FALSE) +
  theme_bw() +
  theme(aspect.ratio = 1)
# Pick the lambda value within 1 SE of the minimum MSE
elastic$lambda.1se
# Print the selected coefficients using the 1 SE lambda
(best_models$elastic <- coef(elastic, s = "lambda.1se"))
```  

#### 15. Fill in the table below with "X"s (like the one at the end of the course notes: a row for each variable, a column for each variable selection method, an "X" in a cell means the variable was included for that variable selection method).

Forgive  my not following the instructions. I found coding the table to be much more satisfying that manually entering it. I switched the rows and columns because I found it much easier to read this way.

```{r}
# Create a matrix to be filled with booleans
models_table <- matrix(ncol = ncol(bodyfat_predictors),
                       nrow = length(best_models))
rownames(models_table) <- c("Best Subset", "Forward", "Backward",
                            "Sequential Rep.", "LASSO", "Elastic Net")
colnames(models_table) <- colnames(bodyfat_predictors)

# Loop through the models and populate the matrix with the included variables
for(i in 1:length(best_models)) {
  model <- best_models[[i]]
  # For the shrinkage methods we saved a matrix of the coefficients
  if("dgCMatrix" %in% class(model)) {
    models_table[i, ] <-
      colnames(bodyfat_predictors) %in%
      rownames(model)[attr(model, "i") + 1] # +1 for 1 based indexing
  }
  # For the other methods we saved the best model
  else {
    models_table[i, ] <-
      colnames(bodyfat_predictors) %in%
      names(model$coefficients)
  }
}

# Print the matrix using X's in place of TRUE's
noquote(ifelse(models_table, "X", ""))
```


#### 16. Now that you have seen the various results from the different methods, pick a subset of variables that you will include in the model. Which variables do you choose to include in the model? Why?

I will include `height`, `neck` and `abdom`. `height` and `abdom` are obvious choices since they are chosen by all the models. `neck` is excluded by the shrinkage models, but it is included by the other ones and logically it seems like neck is a good predictor of BMI. `chest` could be good, but I choose to exclude it because it is highly correlated with `abdom`.

#### 17. Create the multiple linear regression model with the variables you listed in the previous question (alternatively, you can call the best model using $BestModel). Print a summary of the results.

```{r, fig.align='center'}
bodyfat_lm <- lm(brozek ~ height + neck + abdom, data = bodyfat)
summary(bodyfat_lm)
```





### Now that you have chosen a model, the next several questions ask you to check all of the model assumptions. For each assumption, (1) perform appropriate diagnostics to determine if the assumption is violated, and (2) explain whether or not you think the assumption is violated and why you think that. **Note: you can copy (then modify) a lot of your code from Homework 4 to answer these questions.**





#### 18. (L) The Xs vs Y are linear (use all four diagnostics)

```{r, fig.align='center'}
bodyfat_select <- bodyfat %>%
  select(brozek, abdom, height, neck)

# Scatterplot matrix
point_matrix <- function(data) {
  par(pty = "s", las = 1)
  pairs(data, pch = 19, lower.panel = NULL)
}
point_matrix(bodyfat_select)

# residual vs. predictor plots
rpred_col <- function(data, residuals, predictor) {
  ggplot(data = data,
         mapping = aes(x = pull(data, predictor),
                       y = residuals)) +
    geom_point() +
    geom_smooth(se = FALSE, span = 0.95, n = 7, size = 0.5) +
    geom_abline(slope = 0, intercept = 0, linetype = "dashed") +
    theme_minimal() +
    theme(aspect.ratio = 1) +
    xlab(predictor) +
    ylab("Residuals")
}

resid_vs_pred <- function(model) {
  data <- model.frame(model)
  predictors <- attr(model$terms, "term.labels")
  plots <- lapply(predictors, rpred_col, data = data, residuals = resid(model))
  plots["ncol"] <- ceiling(sqrt(length(plots)))
  plots["top"] <- "Residuals vs Predictors"
  do.call(grid.arrange, plots)
}
resid_vs_pred(bodyfat_lm)

# partial regression plots
added_variable_plots <- function(model) {
  predictors <- attr(model$terms, "term.labels")
  rows <- floor(sqrt(length(predictors)))
  cols <- length(predictors) / rows
  par(pty = "s", cex.lab = 1.5, cex.axis = 1.5)
  avPlots(model, layout = c(rows, cols), pch = 19)
}
added_variable_plots(bodyfat_lm)

# residuals vs fitted values
resid_vs_fitted <- function(model) {
  autoplot(model, which = 1, ncol = 1) +
    theme_minimal() +
    theme(aspect.ratio = 1)
}
resid_vs_fitted(bodyfat_lm)
```

This assumption is met. Based on all the plots, the data looks very linear.

#### 19. (I) The residuals are independent (no diagnostic tools - just think about how the data was collected and briefly write your thoughts)

With the information we have, we have no reason to think that the data might be dependent in any way. This assumption is met.

#### 20. (N) The residuals are normally distributed and centered at zero (use all four diagnostics)

```{r, fig.align='center'}
# Boxplot
make_boxplot <- function(model) {
  residuals <- data.frame(residuals = resid(model))
  ggplot(data = residuals, mapping = aes(y = residuals)) +
  geom_boxplot() +
  stat_summary(mapping = aes(x = 0),
               fun = mean, geom = "point",
               shape = 4, size = 2, color = "darkred") +
  theme_classic() +
  theme(aspect.ratio = 2,
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
#  scale_y_continuous(limits = c(-20000, 30000), breaks = seq(-20000, 30000, 10000)) +
  ylab("Residuals") +
  xlab("")
}
make_boxplot(bodyfat_lm)

# Histogram
make_hist <- function(model) {
  residuals <- data.frame(residuals = resid(model))
  ggplot(data = residuals, mapping = aes(x = residuals)) +
  geom_histogram(binwidth = sd(residuals$residuals / 4), mapping = aes(y = ..density..)) +
  stat_function(fun = dnorm,
                color = "blue",
                args = list(mean = 0,
                            sd = sd(residuals$residuals)),
                size = 1.2) +
  xlab("Residuals") +
  ylab("Density") +
  theme_light()
}
make_hist(bodyfat_lm)

# Q-Q
QQPlot <- function(model) {
  autoplot(model, which = 2, ncol = 1) +
    theme_bw() +
    theme(aspect.ratio = 1)
}
QQPlot(bodyfat_lm)

# Shapiro-Wilk
shapiro.test(bodyfat_lm$residuals)
```

The boxplot and histogram look great. The Q-Q plot shows a little bit of deviation on the tails. The Shapiro-Wilks p-value is surprisingly small, but not quite significant at $\alpha=0.05$. Overall, the residuals look pretty normal. This assumption is met.

#### 21. (E) The residuals have equal/constant variance across all values of X (use the one diagnostic tool)

```{r}
resid_vs_fitted(bodyfat_lm)
```

The residuals vs fitted values plot looks great, with no clear trends. This assumption is met.

#### 22. (A) The model describes all observations (i.e., there are no influential points) (use at least four diagnostic tools)

```{r, fig.align='center'}
# Cook's Distance
cooksd_plot <- function(model, nLabels = 3) {
  cooks_d <- cooks.distance(model)
  top_cd <- as.numeric(names(sort(cooks_d, decreasing = TRUE)[1:nLabels]))
  
  ggplot() +
  geom_point(data = tibble(cooks_d),
             mapping = aes(x = as.numeric(names(cooks_d)), 
                           y = cooks_d)) +
  geom_text(mapping = aes(x = top_cd,
                          y = cooks_d[top_cd] + max(cooks_d) / 40,
                          label = top_cd)) +
  theme_bw() +
  ylab("Cook's Distance") +
  xlab("Observation Number") +
  geom_hline(mapping = aes(yintercept = 4 / length(cooks_d)),
             color = "red", linetype = "dashed") +
  theme(aspect.ratio = 1)
}
cooksd_plot(bodyfat_lm)

# DFBETAS
dfb_col <- function(df_betas, predictor, nLabels = 3) {
  # Find which observations have the highest dfbetas
   top_vals <- df_betas[predictor] %>%
    arrange(desc(abs(eval(parse(text = predictor))))) %>%
    .[1:nLabels,] %>%
    pull(predictor)
  top_ind <- which(pull(df_betas, predictor) %in% top_vals)
  
  out <- ggplot() +
    geom_point(data = df_betas,
               mapping = aes(x = as.numeric(rownames(df_betas)),
                             y = abs(pull(df_betas, predictor)))) +
     geom_text(mapping = aes(x = top_ind,
                             y = abs(pull(df_betas, predictor)[top_ind]) + 0.07,
                             label = top_ind)) +
    theme_bw() +
    theme(aspect.ratio = 1) +
    ylab("Abs of DFBETAS") +
    xlab("Observation Number") +
    ggtitle(predictor)
  
  if(length(dfbetas) <= 30) {
    out <- out +
      geom_hline(mapping = aes(yintercept = 1),
                 color = "red", linetype = "dashed")
  }else {
    out <- out +
      geom_hline(mapping = aes(yintercept = 2 / sqrt(length(dfbetas))),
                 color = "red", linetype = "dashed")
  }
  return(out)
}


plot_dfbetas <- function(model, nLabels = 3) {
  predictors <- attr(model$terms, "term.labels")
  df_betas <- as_tibble(dfbetas(model)[, predictors])

  plots <- lapply(predictors, dfb_col, df_betas = df_betas)
  plots["ncol"] <- ceiling(sqrt(length(plots)))
  do.call(grid.arrange, plots)
}
plot_dfbetas(bodyfat_lm)

# DFFITS
plot_dffits <- function(model, nLabels = 3) {
  df_fits <- dffits(model)
  top_dff <- as.numeric(names(sort(abs(df_fits), decreasing = TRUE)[1:nLabels]))
  
  df_fits_plot <- ggplot() + 
    geom_point(data = tibble(df_fits),
               mapping = aes(x = as.numeric(names(df_fits)), 
                             y = abs(df_fits))) +
    geom_text(mapping = aes(x = top_dff,
                            y = abs(df_fits[top_dff]) + 0.05,
                            label = top_dff)) +
    theme_bw() +
    ylab("Absolute Value of DFFITS for Y") +
    xlab("Observation Number") +
    theme(aspect.ratio = 1)
  if(length(df_fits) <= 30) {
    df_fits_plot +
      geom_hline(mapping = aes(yintercept = 
                                 2 * sqrt(length(model$coefficients) /
                                                       length(df_fits))),
                 color = "red", linetype = "dashed")
  }else {
    df_fits_plot +
      geom_hline(mapping = aes(yintercept = 1),
                 color = "red", linetype = "dashed")
  }
}
plot_dffits(bodyfat_lm)
```

Referring back to the three plots for normality, none of those show any distinct outliers. Though cooks distance shows a number of points beyond the cut off, the points don't appear very distant from the rest of the data. The DFBETAS and DFFITS look great. There are no obvious influential points; this assumption is met.

#### 23. (R) Additional predictor variables are not required (no diagnostic tools - just think about the variables you have and if there are other variables you think would help predict the response)

The original set of predictors seemed pretty comprehensive. In fact, we saw that we had more variables than necessary. I can't think of anything else that would help predict body fat. This assumption is met.

#### 24. No multicollinearity  (use all three diagnostics)

```{r, fig.align='center'}
# Variance Inflation Factors
(vifs <- vif(bodyfat_lm))
mean(vifs)

# Correlation
show_cor <- function(data) {
  par(mfrow = c(1, 2))
  corrplot(cor(data), method = "number", type = "upper", diag = F, tl.col = "#1f3366", cl.pos = "n")
  title("Correlation Coefficients")
  corrplot(cor(data), type = "upper", diag = F, tl.col = "#1f3366", cl.pos = "n")
  title("Correlation Matrix")
}
show_cor(bodyfat_select)

# Scatterplot matrix
point_matrix(bodyfat_select)
```

Based on the scatterplots and the correlations coefficients, `neck` and `abdom` might cause problems, but the variance inflation factors are fine and the correlation coefficient isn't too bad. We do see that there is a problem when we notice that the coefficient for `neck` is negative when we would expect it to be positive. This assumtion is still not met.

#### 25. Given the results from your model assumption checking, what would you do next to continue this analysis?

This models seems fairly good except the persistent multicollinearity issue. I would address that and then proceed with hypothesis tests and report confidence intervals.

#### 26. Briefly summarize what you learned, personally, from this analysis about the statistics, model fitting process, etc.

Fro this assignment I took away a lot of understanding of the various variable selection models as well as ridge regression. I studied up on the algorithm of each method and the differences between them.

#### 27. Briefly summarize what you learned from this analysis *to a non-statistician*. Write a few sentences about (1) the purpose of this data set and analysis and (2) what you learned about this data set from your analysis. Write your response as if you were addressing a business manager (avoid using statistics jargon) and just provide the main take-aways.

The purpose of this data was to determine an easier way of measuring body fat than submergence. In the last analysis we learned that we could possibly come up with such a method, but that we needed to choose the predictors of body fat more carefully. The purpose of this analysis was to make reasonable choices and come up with a concrete model. We discovered that we can predict body fat based on height, abdomen and neck measurements by the following equation $\text{Body Fat}=4.9-0.47\times\text{Height}-0.58\times\text{Neck}+0.75\times\text{Abdomen}$. Our model is obviously not fantastic because we would expect increased neck size to be a predictor of increased - not decreased - body fat. We would still have to adress some issues before using this model.